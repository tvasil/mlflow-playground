{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from so_tag_classifier_core import (text_prepare, binarize_ys, tokenize_and_stem, transform_y)\n",
    "\n",
    "import dill\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, accuracy_score, average_precision_score, \n",
    "                             f1_score, precision_score, make_scorer)\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = configs.get(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = configs.get(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "TRACKING_URI = configs.get(\"TRACKING_URI\")\n",
    "BUCKET = configs.get(\"BUCKET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment('stackoverlow-classifier')\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Python class \n",
    "\n",
    "This custom class lets us extract multiple artifacts from the `model` registry, not just the `classifier`. Also, it allows us to define a custom inference function (`.predict`), which will also transform the output data from a 100-element long matrix to just the labels we want to predict, along with their corresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelClassifierPipelineWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.binarizer = dill.load(context.artifacts[\"binarizer\"])\n",
    "        self.pipeline = dill.load(context.artifacts[\"pipeline\"])\n",
    "        \n",
    "\n",
    "    def predict(self, context, document):\n",
    "        \"\"\"\n",
    "        Make a label prediction for an arbitrary number of documents/texts\n",
    "        \"\"\"\n",
    "        \n",
    "        vals = document.text.tolist()\n",
    "        raw_preds = self.pipeline.predict(vals)\n",
    "        preds = self.binarizer.inverse_transform(raw_preds)\n",
    "        \n",
    "        probs = self.pipeline.predict_proba(vals)\n",
    "        all_probs_dict = [dict(zip(self.binarizer.classes_, prob)) for prob in probs]\n",
    "        to_return = []\n",
    "        for pred, probs_dict in zip(preds, all_probs_dict):\n",
    "            to_return.append({x:probs_dict[x] for x in probs_dict if x in pred})\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_test, y_preds):\n",
    "    accuracy = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds, average=\"weighted\")\n",
    "    avg_precision = average_precision_score(y_test, y_preds)\n",
    "    precision = precision_score(y_test, y_preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \n",
    "            \"f1\": f1, \n",
    "            \"avg_precision\": avg_precision, \n",
    "            \"precision\": precision}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=\"/Users/tania/tvasil/stackoverflow-topic-classifier/data/full_body_clean.csv\"\n",
    "df = pd.read_csv(data_file)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].values, \n",
    "                                                    df['tags'].values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "binarizer, y_train_binarized, y_test_binarized = binarize_ys(y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training \n",
    "### 1. BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_search_space = {\n",
    "    \"tfidf__min_df\": Integer(5, 100),\n",
    "    \"tfidf__max_df\": Real(0.5, 0.99, prior='log-uniform'),\n",
    "    \"clf\": [ClassifierChain(LogisticRegression(random_state=42,\n",
    "                                                           dual=False, \n",
    "                                                           solver=\"liblinear\", \n",
    "                                                           max_iter=1000), \n",
    "                                             cv=3)],\n",
    "    \"clf__base_estimator__C\": Real(0.000001, 5e5, prior=\"uniform\"),\n",
    "    \"clf__base_estimator__penalty\": ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the search space and defaults \n",
    "estimators = [('preprocessor', FunctionTransformer(text_prepare, kw_args={'join_symbol': ' '})), \n",
    "              ('tfidf', TfidfVectorizer(tokenizer=tokenize_and_stem, \n",
    "                                        ngram_range=(1, 3),\n",
    "                                        norm='l2')),\n",
    "              ('clf', ClassifierChain(LogisticRegression()))\n",
    "             ]\n",
    "\n",
    "scoring = {'f1': make_scorer(f1_score, average= 'weighted'), \n",
    "           'average_precision': 'average_precision'}\n",
    "\n",
    "### Create the Pipeline and RSCV objects \n",
    "training_pipe = Pipeline(estimators, verbose=True)\n",
    "hyperoptsearch = BayesSearchCV(training_pipe,\n",
    "                          #param_grid=search_space,\n",
    "                          search_spaces=bayes_search_space, \n",
    "                          scoring=make_scorer(f1_score, average= 'weighted'),\n",
    "                          refit=True, \n",
    "                          return_train_score=True, \n",
    "                          cv=3, \n",
    "                          verbose=10, \n",
    "                          n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Second attempt at BayesSearch\") as run:\n",
    "    hyperoptsearch.fit(X_train, y_train_binarized)\n",
    "    signature = infer_signature(X_train, hyperoptsearch.best_estimator_.predict(X_train))\n",
    "    print(\"Logged data and model in run: {}\".format(run.info.run_id))\n",
    "    \n",
    "    ## CAPTURE METRICS\n",
    "    y_test_pred_binarized = hyperoptsearch.best_estimator_.predict(X_test)\n",
    "    class_report = classification_report(\n",
    "                                y_test_binarized, \n",
    "                                y_test_pred_binarized, \n",
    "                                target_names=binarizer.classes_, \n",
    "                                zero_division=1\n",
    "                            )\n",
    "    metrics = eval_metrics(y_test_binarized, y_test_pred_binarized)\n",
    "\n",
    "#     mlflow.log_params(rs.named_steps) # log pipeline steps -- could be improved\n",
    "#     mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    \n",
    "    ## CREATE AND SAVE ARTIFACTS\n",
    "    \n",
    "    pipeline_path = \"models/classifier.pkl\"\n",
    "    binarizer_path = \"models/binarizer.pkl\"\n",
    "    class_report_path = \"metrics/classification_report.txt\"\n",
    "    \n",
    "    dill.dump(hyperoptsearch.best_estimator_, pipeline_path)\n",
    "    dill.dump(binarizer, binarizer_path)\n",
    "    with open(class_report_path, 'w') as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "    artifacts = {\n",
    "        \"pipeline\": pipeline_path,\n",
    "        \"binarizer\": binarizer_path,\n",
    "        \"classification_report\": class_report_path\n",
    "    }\n",
    "\n",
    "    mlflow_pyfunc_model_path = \"so_pyfunc_model\"\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=mlflow_pyfunc_model_path, \n",
    "        python_model=MultiLabelClassifierPipelineWrapper(), \n",
    "        artifacts=artifacts,\n",
    "        conda_env=conda_env, \n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('preprocessor', FunctionTransformer(text_prepare, kw_args={'join_symbol': ' '})), \n",
    "              ('tfidf', TfidfVectorizer(tokenizer=tokenize_and_stem, \n",
    "                                        ngram_range=(1, 3),\n",
    "                                        norm='l2')),\n",
    "              ('clf', ClassifierChain(LogisticRegression(random_state=42,\n",
    "                                                         dual=False, \n",
    "                                                         max_iter=1000, \n",
    "                                                         solver='liblinear'), \n",
    "                                      cv=3))\n",
    "             ]\n",
    "\n",
    "search_space = {\"tfidf__min_df\": randint(5, 100),\n",
    "                \"tfidf__max_df\": uniform(0.01, 0.98),\n",
    "                \"clf__base_estimator__C\": uniform(0.000001, 50000),\n",
    "                \"clf__base_estimator__penalty\": ['l1', 'l2']}\n",
    "\n",
    "\n",
    "scoring = {'f1': make_scorer(f1_score, average= 'weighted'), \n",
    "           'average_precision': 'average_precision'}\n",
    "\n",
    "### Create the Pipeline and RSCV objects \n",
    "training_pipe = Pipeline(estimators, verbose=True)\n",
    "hyperoptsearch = RandomizedSearchCV(training_pipe,\n",
    "                                    param_distributions=search_space,\n",
    "                                    scoring=make_scorer(f1_score, average= 'weighted'),\n",
    "                                    refit=True, \n",
    "                                    n_iter=3,\n",
    "                                    return_train_score=True, \n",
    "                                    cv=3, \n",
    "                                    verbose=10, \n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/16 12:11:32 WARNING mlflow.sklearn.utils: Truncated the value of the key `estimator`. Truncated value: `Pipeline(memory=None,\n",
      "         steps=[('preprocessor',\n",
      "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                                     func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                             ...`\n",
      "2020/12/16 12:11:32 WARNING mlflow.sklearn.utils: Truncated the value of the key `param_distributions`. Truncated value: `{'tfidf__min_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9d1e7c57d0>, 'tfidf__max_df': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f9d1e7c5190>, 'clf__base_estimator__C': <scipy.stats._distn_infrastructure.rv_froz...`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed: 100.0min remaining: 200.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed: 108.6min remaining: 135.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed: 114.0min remaining: 91.2min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed: 115.9min remaining: 58.0min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 118.3min remaining: 33.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 165.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 165.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 3) Processing preprocessor, total=   3.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total= 1.5min\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 4.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/16 15:09:00 WARNING mlflow.sklearn.utils: Failed to autolog artifacts for RandomizedSearchCV. Logging error: unhashable type: 'numpy.ndarray'\n",
      "2020/12/16 15:11:38 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://tvasil-ml-models/1/83ae738e766b4383b124e33bd4415299/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n",
      "2020/12/16 15:11:38 WARNING mlflow.sklearn.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol':...`\n",
      "2020/12/16 15:11:38 WARNING mlflow.sklearn.utils: Truncated the value of the key `preprocessor`. Truncated value: `FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol': ' '}, validate=Fa...`\n",
      "2020/12/16 15:11:38 WARNING mlflow.sklearn.utils: Truncated the value of the key `tfidf`. Truncated value: `TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf`. Truncated value: `ClassifierChain(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                  dual=False,\n",
      "                                                  fit_intercept=True,\n",
      "                                       ...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf__base_estimator`. Truncated value: `LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol':...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `preprocessor`. Truncated value: `FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol': ' '}, validate=Fa...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `tfidf`. Truncated value: `TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf`. Truncated value: `ClassifierChain(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                  dual=False,\n",
      "                                                  fit_intercept=True,\n",
      "                                       ...`\n",
      "2020/12/16 15:11:39 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf__base_estimator`. Truncated value: `LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42...`\n",
      "2020/12/16 15:11:40 WARNING mlflow.sklearn.utils: Truncated the value of the key `steps`. Truncated value: `[('preprocessor', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol':...`\n",
      "2020/12/16 15:11:40 WARNING mlflow.sklearn.utils: Truncated the value of the key `preprocessor`. Truncated value: `FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "                    func=<function text_prepare at 0x7f9d3cbe8170>,\n",
      "                    inv_kw_args=None, inverse_func=None,\n",
      "                    kw_args={'join_symbol': ' '}, validate=Fa...`\n",
      "2020/12/16 15:11:40 WARNING mlflow.sklearn.utils: Truncated the value of the key `tfidf`. Truncated value: `TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_...`\n",
      "2020/12/16 15:11:40 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf`. Truncated value: `ClassifierChain(base_estimator=LogisticRegression(C=1.0, class_weight=None,\n",
      "                                                  dual=False,\n",
      "                                                  fit_intercept=True,\n",
      "                                       ...`\n",
      "2020/12/16 15:11:40 WARNING mlflow.sklearn.utils: Truncated the value of the key `clf__base_estimator`. Truncated value: `LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42...`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged data and model in run: 83ae738e766b4383b124e33bd4415299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/12/16 15:15:04 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://tvasil-ml-models/1/83ae738e766b4383b124e33bd4415299/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Third attempt at RanzomizedSearchCV\") as run:\n",
    "    hyperoptsearch.fit(X_train, y_train_binarized)\n",
    "    signature = infer_signature(X_train, hyperoptsearch.best_estimator_.predict(X_train))\n",
    "    print(\"Logged data and model in run: {}\".format(run.info.run_id))\n",
    "    \n",
    "    ## CAPTURE METRICS\n",
    "    y_test_pred_binarized = hyperoptsearch.best_estimator_.predict(X_test)\n",
    "    class_report = classification_report(\n",
    "                                y_test_binarized, \n",
    "                                y_test_pred_binarized, \n",
    "                                target_names=binarizer.classes_, \n",
    "                                zero_division=1\n",
    "                            )\n",
    "    metrics = eval_metrics(y_test_binarized, y_test_pred_binarized)\n",
    "\n",
    "#     mlflow.log_params(rs.named_steps) # log pipeline steps -- could be improved\n",
    "#     mlflow.log_params(params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    \n",
    "    ## CREATE AND SAVE ARTIFACTS\n",
    "    \n",
    "    pipeline_path = \"models/classifier.pkl\"\n",
    "    binarizer_path = \"models/binarizer.pkl\"\n",
    "    class_report_path = \"metrics/classification_report.txt\"\n",
    "\n",
    "    with open(pipeline_path, 'wb') as f:\n",
    "        dill.dump(hyperoptsearch.best_estimator_, f)\n",
    "    with open(binarizer_path, 'wb') as f:\n",
    "        dill.dump(binarizer, f)\n",
    "    with open(class_report_path, 'w') as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "    artifacts = {\n",
    "        \"pipeline\": pipeline_path,\n",
    "        \"binarizer\": binarizer_path,\n",
    "        \"classification_report\": class_report_path\n",
    "    }\n",
    "\n",
    "    mlflow_pyfunc_model_path = \"so_pyfunc_model\"\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=mlflow_pyfunc_model_path, \n",
    "        python_model=MultiLabelClassifierPipelineWrapper(), \n",
    "        artifacts=artifacts,\n",
    "        conda_env=conda_env, \n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlflow]",
   "language": "python",
   "name": "conda-env-mlflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
