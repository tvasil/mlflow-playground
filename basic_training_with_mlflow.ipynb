{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from so_tag_classifier_core import (text_prepare, binarize_ys, tokenize_and_stem, transform_y)\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, average_precision_score, f1_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = configs.get(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = configs.get(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "TRACKING_URI = configs.get(\"TRACKING_URI\")\n",
    "BUCKET = configs.get(\"BUCKET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment('stackoverlow-classifier')\n",
    "#mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract conda env\n",
    "\n",
    "This environment file with later be passed on to the model definition directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda env export > environment.yml --no-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"environment.yml\") as f:\n",
    "    conda_env = yaml.safe_load(f)\n",
    "    conda_env.pop(\"prefix\")\n",
    "    conda_env[\"channels\"].extend([\"anaconda\", \"conda-forge\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Python class \n",
    "\n",
    "This custom class lets us extract multiple artifacts from the `model` registry, not just the `classifier`. Also, it allows us to define a custom inference function (`.predict`), which will also transform the output data from a 100-element long matrix to just the labels we want to predict, along with their corresponding probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelClassifierPipelineWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.binarizer = joblib.load(context.artifacts[\"binarizer\"])\n",
    "        self.pipeline = joblib.load(context.artifacts[\"pipeline\"])\n",
    "        \n",
    "\n",
    "    def predict(self, context, document):\n",
    "        \"\"\"\n",
    "        Make a label prediction for an arbitrary number of documents/texts\n",
    "        \"\"\"\n",
    "        \n",
    "        vals = document.text.tolist()\n",
    "        raw_preds = self.pipeline.predict(vals)\n",
    "        preds = self.binarizer.inverse_transform(raw_preds)\n",
    "        \n",
    "        probs = self.pipeline.predict_proba(vals)\n",
    "        all_probs_dict = [dict(zip(self.binarizer.classes_, prob)) for prob in probs]\n",
    "        to_return = []\n",
    "        for pred, probs_dict in zip(preds, all_probs_dict):\n",
    "            to_return.append({x:probs_dict[x] for x in probs_dict if x in pred})\n",
    "        return to_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_test, y_preds):\n",
    "    accuracy = accuracy_score(y_test, y_preds)\n",
    "    f1 = f1_score(y_test, y_preds, average=\"weighted\")\n",
    "    avg_precision = average_precision_score(y_test, y_preds)\n",
    "    precision = precision_score(y_test, y_preds, average=\"weighted\")\n",
    "    return accuracy, f1, avg_precision, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file=\"/Users/tania/tvasil/stackoverflow-topic-classifier/data/full_body_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(tfidf_n_gram_range = (1, 3),\n",
    "              tfidf_max_df=0.9,\n",
    "              tfidf_min_df=5,\n",
    "              tfidf_norm=\"l2\",\n",
    "              clf_c=3,\n",
    "              clf_penalty=\"l1\",\n",
    "              clf_dual=False,\n",
    "              clf_solver=\"liblinear\",\n",
    "              cv=3\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].values, \n",
    "                                                    df['tags'].values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "binarizer, y_train_binarized, y_test_binarized = binarize_ys(y_train, y_test)\n",
    "\n",
    "estimators = [('preprocessor', FunctionTransformer(text_prepare, kw_args={'join_symbol': ' '})), \n",
    "          ('tfidf', TfidfVectorizer(tokenizer=tokenize_and_stem, \n",
    "                                    ngram_range=params['tfidf_n_gram_range'], \n",
    "                                    max_df=params['tfidf_max_df'], \n",
    "                                    min_df=params['tfidf_min_df'],\n",
    "                                    norm=params['tfidf_norm'])),\n",
    "          ('clf', ClassifierChain(LogisticRegression(C=params['clf_c'], \n",
    "                                                     penalty=params['clf_penalty'], \n",
    "                                                     dual=params['clf_dual'], \n",
    "                                                     solver=params['clf_solver']), \n",
    "                                  random_state=42,\n",
    "                                  cv=params['cv']))\n",
    "         ]\n",
    "\n",
    "training_pipe = Pipeline(estimators, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 3) Processing preprocessor, total=   3.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total= 1.1min\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 3.3min\n",
      "Logged data and model in run: e5b2d5de8e7f483087337483b0e87942\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"Fix mapping function\") as run:\n",
    "    training_pipe.fit(X_train, y_train_binarized)\n",
    "    signature = infer_signature(X_train, training_pipe.predict(X_train))\n",
    "    print(\"Logged data and model in run: {}\".format(run.info.run_id))\n",
    "    \n",
    "    ## CAPTURE METRICS\n",
    "    y_test_pred_binarized = training_pipe.predict(X_test)\n",
    "    class_report = classification_report(\n",
    "                                y_test_binarized, \n",
    "                                y_test_pred_binarized, \n",
    "                                target_names=binarizer.classes_, \n",
    "                                zero_division=1\n",
    "                            )\n",
    "    accuracy, f1, avg_precision, precision = eval_metrics(y_test_binarized, y_test_pred_binarized)\n",
    "\n",
    "    mlflow.log_params(training_pipe.named_steps) # log pipeline steps -- could be improved\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"test_f1\", f1)\n",
    "    mlflow.log_metric(\"test_avg_precision\", avg_precision)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    \n",
    "    \n",
    "    ## CREATE AND SAVE ARTIFACTS\n",
    "    \n",
    "    pipeline_path = \"models/classifier.pkl\"\n",
    "    binarizer_path = \"models/binarizer.pkl\"\n",
    "    tags_path = \"models/tags.pkl\"\n",
    "    class_report_path = \"metrics/classification_report.txt\"\n",
    "\n",
    "    \n",
    "    \n",
    "    joblib.dump(training_pipe, pipeline_path)\n",
    "    joblib.dump(binarizer, binarizer_path)\n",
    "    with open(class_report_path, 'w') as f:\n",
    "        f.write(class_report)\n",
    "\n",
    "    # Create an `artifacts` dictionary that assigns a unique name to the saved model file.\n",
    "    # This dictionary will be passed to `mlflow.pyfunc.save_model`, which will copy the model file\n",
    "    # into the new MLflow Model's directory.\n",
    "    artifacts = {\n",
    "        \"pipeline\": pipeline_path,\n",
    "        \"binarizer\": binarizer_path,\n",
    "        \"classification_report\": class_report_path\n",
    "    }\n",
    "\n",
    "    mlflow_pyfunc_model_path = \"so_pyfunc_model\"\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=mlflow_pyfunc_model_path, \n",
    "        python_model=MultiLabelClassifierPipelineWrapper(), \n",
    "        artifacts=artifacts,\n",
    "        conda_env=conda_env, \n",
    "        signature=signature\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_s3 = \"s3://tvasil-ml-models/1/ecd8d0a55a264405a3f6e824f17b63ca/artifacts/so_pyfunc_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_path_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't figure out how to load a custom model ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to compile the Kotlin code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  I can't figure out how to load a custom model ...\n",
       "1                     How to compile the Kotlin code"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict = pd.DataFrame(data={\"text\": [\"I can't figure out how to load a custom model from Tensorflow into my Python function\",\n",
    "                                         \"How to compile the Kotlin code\"]}, \n",
    "                          index=[0, 1])\n",
    "to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"text\":\"I can\\'t figure out how to load a custom model from Tensorflow into my Python function\"},{\"text\":\"How to compile the Kotlin code\"}]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'python': 0.9870509228172972, 'tensorflow': 0.8195176085539446},\n",
       " {'android': 0.9373731083606335, 'kotlin': 0.999999999999936}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(data=to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-f923d991bf00>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-f923d991bf00>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print('Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 213, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\\\", line 424, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/model.py\\\", line 254, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \\\"<ipython-input-6-b1024ab02d67>\\\", line 14, in predict\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\\\", line 119, in <lambda>\\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/pipeline.py\\\", line 407, in predict\\n    Xt = transform.transform(Xt)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1880, in transform\\n    X = super().transform(raw_documents)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1250, in transform\\n    _, X = self._count_vocab(raw_documents, fixed_vocab=True)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1110, in _count_vocab\\n    for feature in analyze(doc):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 106, in _analyze\\n    doc = tokenizer(doc)\\n  File \\\"/opt/mlflow/src/so-tag-classifier-core/core/so_tag_classifier_core/preprocessing_steps.py\\\", line 171, in tokenize_and_stem\\n    tokenized_list = word_tokenize(text)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/tokenize/__init__.py\\\", line 129, in word_tokenize\\n    sentences = [text] if preserve_line else sent_tokenize(text, language)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/tokenize/__init__.py\\\", line 106, in sent_tokenize\\n    tokenizer = load(\\\"tokenizers/punkt/{0}.pickle\\\".format(language))\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 752, in load\\n    opened_resource = _open(resource_url)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 877, in _open\\n    return find(path_, path + [\\\"\\\"]).open()\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 585, in find\\n    raise LookupError(resource_not_found)\\nLookupError: \\n**********************************************************************\\n  Resource \\u001b[93mpunkt\\u001b[0m not found.\\n  Please use the NLTK Downloader to obtain the resource:\\n\\n  \\u001b[31m>>> import nltk\\n  >>> nltk.download('punkt')\\n  \\u001b[0m\\n  For more information see: https://www.nltk.org/data.html\\n\\n  Attempted to load \\u001b[93mtokenizers/punkt/PY3/english.pickle\\u001b[0m\\n\\n  Sea')\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print('Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 213, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/__init__.py\\\", line 424, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/mlflow/pyfunc/model.py\\\", line 254, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \\\"<ipython-input-6-b1024ab02d67>\\\", line 14, in predict\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\\\", line 119, in <lambda>\\n    out = lambda *args, **kwargs: self.fn(obj, *args, **kwargs)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/pipeline.py\\\", line 407, in predict\\n    Xt = transform.transform(Xt)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1880, in transform\\n    X = super().transform(raw_documents)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1250, in transform\\n    _, X = self._count_vocab(raw_documents, fixed_vocab=True)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 1110, in _count_vocab\\n    for feature in analyze(doc):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\\\", line 106, in _analyze\\n    doc = tokenizer(doc)\\n  File \\\"/opt/mlflow/src/so-tag-classifier-core/core/so_tag_classifier_core/preprocessing_steps.py\\\", line 171, in tokenize_and_stem\\n    tokenized_list = word_tokenize(text)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/tokenize/__init__.py\\\", line 129, in word_tokenize\\n    sentences = [text] if preserve_line else sent_tokenize(text, language)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/tokenize/__init__.py\\\", line 106, in sent_tokenize\\n    tokenizer = load(\\\"tokenizers/punkt/{0}.pickle\\\".format(language))\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 752, in load\\n    opened_resource = _open(resource_url)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 877, in _open\\n    return find(path_, path + [\\\"\\\"]).open()\\n  File \\\"/miniconda/envs/custom_env/lib/python3.7/site-packages/nltk/data.py\\\", line 585, in find\\n    raise LookupError(resource_not_found)\\nLookupError: \\n**********************************************************************\\n  Resource \\u001b[93mpunkt\\u001b[0m not found.\\n  Please use the NLTK Downloader to obtain the resource:\\n\\n  \\u001b[31m>>> import nltk\\n  >>> nltk.download('punkt')\\n  \\u001b[0m\\n  For more information see: https://www.nltk.org/data.html\\n\\n  Attempted to load \\u001b[93mtokenizers/punkt/PY3/english.pickle\\u001b[0m\\n\\n  Sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlflow]",
   "language": "python",
   "name": "conda-env-mlflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
